{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "gKXu0XgAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Yongjian Deng", "affiliation": "City University of Hong Kong", "interests": ["Neuromorphic vision", "Cross-modal learning", "Graph-based representation"], "email_domain": "@bjut.edu.cn", "citedby": 543, "publications": {"gKXu0XgAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RGBD salient object detection via disentangled cross-modal fusion", "pub_year": "2020"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:u-x6o8ySG0sC", "num_citations": 94, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14280591924091101910", "cites_id": ["14280591924091101910"]}, "gKXu0XgAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TransIFC: Invariant cues-aware feature concentration learning for efficient fine-grained bird image classification", "pub_year": "2023"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:Y0pCki6q_DkC", "num_citations": 83, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12560914388240779815", "cites_id": ["12560914388240779815"]}, "gKXu0XgAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Voxel Graph CNN for Object Classification with Event Cameras", "pub_year": "2022"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:UeHWp8X0CEIC", "num_citations": 63, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16843644147083234108,8623588827452034900", "cites_id": ["16843644147083234108", "8623588827452034900"]}, "gKXu0XgAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MVF-Net: A multi-view fusion network for event-based object classification", "pub_year": "2022"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:d1gkVwhDpl0C", "num_citations": 52, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6198119774260970920", "cites_id": ["6198119774260970920"]}, "gKXu0XgAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Orientation cues-aware facial relationship representation for head pose estimation via transformer", "pub_year": "2023"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:_FxGoFyzp5QC", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1982336277273159400", "cites_id": ["1982336277273159400"]}, "gKXu0XgAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Amae: Adaptive motion-agnostic encoder for event-based object classification", "pub_year": "2020"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:u5HHmVD_uO8C", "num_citations": 44, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9529057238613960324", "cites_id": ["9529057238613960324"]}, "gKXu0XgAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vmv-gcn: Volumetric multi-view based graph cnn for event stream classification", "pub_year": "2022"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:zYLM7Y9cAGgC", "num_citations": 39, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1107658598293445483", "cites_id": ["1107658598293445483"]}, "gKXu0XgAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Tokenhpe: Learning orientation tokens for efficient head pose estimation via transformers", "pub_year": "2023"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:WF5omc3nYNoC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18298219609601712432", "cites_id": ["18298219609601712432"]}, "gKXu0XgAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning from images: A distillation learning framework for event cameras", "pub_year": "2021"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:2osOgNQ5qMEC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15853113860900922012", "cites_id": ["15853113860900922012"]}, "gKXu0XgAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CNN-Based RGB-D Salient Object Detection: Learn, Select, and Fuse", "pub_year": "2021"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:IjCSPb-OGe4C", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12046445900747860270", "cites_id": ["12046445900747860270"]}, "gKXu0XgAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Dynamic GCN with Cross-Representation Distillation for Event-Based Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:Se3iqnhoufwC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9444219803646863477,2791009288955506651", "cites_id": ["9444219803646863477", "2791009288955506651"]}, "gKXu0XgAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Event voxel set transformer for spatiotemporal representation learning on event streams", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:eQOLeE2rZwMC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14551284757712280348", "cites_id": ["14551284757712280348"]}, "gKXu0XgAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EISNet: A Multi-Modal Fusion Network for Semantic Segmentation with Events and Images", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:UebtZRa9Y70C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16864338582728880815", "cites_id": ["16864338582728880815"]}, "gKXu0XgAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Disentangled cross-modal transformer for RGB-d salient object detection and beyond", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:LkGwnXOMwfcC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14530683038323327672", "cites_id": ["14530683038323327672"]}, "gKXu0XgAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Event tubelet compressor: Generating compact representations for event-based action recognition", "pub_year": "2022"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:YsMSGLbcyi4C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6712779978310760418", "cites_id": ["6712779978310760418"]}, "gKXu0XgAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Video Frame Interpolation via Direct Synthesis with the Event-based Reference", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:0EnyYjriUFMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18101270391232521406", "cites_id": ["18101270391232521406"]}, "gKXu0XgAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EventAug: Multifaceted Spatio-Temporal Data Augmentation Methods for Event-based Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:MXK_kJrjxJIC", "num_citations": 0}, "gKXu0XgAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hifoots: A Highly Efficient DDoS Attack Detection Scheme Deployed in Smart IoT Homes", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:5nxA0vEk-isC", "num_citations": 0}, "gKXu0XgAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SAM-Event-Adapter: Adapting Segment Anything Model for Event-RGB Semantic Segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:8k81kl-MbHgC", "num_citations": 0}, "gKXu0XgAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Event-based Video Frame Interpolation with Edge Guided Motion Refinement", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:hqOjcs7Dif8C", "num_citations": 0}, "gKXu0XgAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Data-efficient Event Camera Pre-training via Disentangled Masked Modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:roLk4NBRz8UC", "num_citations": 0}, "gKXu0XgAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Interpretation on Multi-modal Visual Fusion", "pub_year": "2023"}, "filled": false, "author_pub_id": "gKXu0XgAAAAJ:ufrVoPGSRksC", "num_citations": 0}}, "citedby5y": 543, "hindex": 10, "hindex5y": 10, "i10index": 10, "i10index5y": 10, "cites_per_year": {"2021": 33, "2022": 61, "2023": 156, "2024": 288}, "updated": "2024-10-10 08:23:40.318842"}